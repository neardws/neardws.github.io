# 边缘视觉智能研究进展 — 讲稿

> 汇报人：许新操 | 2026年2月8日 组会报告

---

## 第1页：封面

各位老师、同学们，大家好。我是电子科技大学深圳高等研究院数据智能研究中心的许新操。今天我汇报的题目是《边缘视觉智能研究进展》。

---

## 第2页：汇报提纲

本次汇报分为四个部分：首先是个人简介，然后介绍研究背景，接着是研究内容的详细展开，最后是后续的工作计划。

---

## 第3页：个人基本信息

简单介绍一下我自己。我1994年出生，2023年6月在重庆大学获得工学博士学位，同年7月进入电子科大深研院从事博士后研究，2025年9月晋升为副研究员。我的研究方向是边缘视觉智能。

在项目方面，我主持了2025年广东省自然科学基金面上项目和2023年中国博士后科学基金面上资助。

在学术成果方面，代表性工作包括：IEEE T-ITS 2024关于车路协同异构信息融合的工作，IEEE TCE 2024关于数字孪生感知-上传-资源联合优化的工作，ECAI 2025关于小波解耦与对比学习的跨模态表征工作，JSA 2023关于NOMA环境下任务卸载的工作，以及电子学报2021关于边缘计算同信道干扰抑制的工作。

---

## 第4页：汇报提纲（过渡）

下面进入第二部分，研究背景。

---

## 第5页：研究背景——边缘视觉智能趋势与挑战

当前边缘视觉智能呈现三大趋势：第一，视觉AI正从云端下沉到边缘，这是实时性和隐私保护的双重需求驱动的；第二，应用场景爆发式增长，涵盖自动驾驶、工业机器人、智能安防等领域；第三，设备形态日趋多样，从服务器到MCU微控制器都有部署需求。

但同时也面临三重挑战：**资源难适配**——异构设备的算力差异巨大；**部署难自动**——模型到设备的适配仍需大量人工介入；**闭环难贯通**——从算法到部署到应用的全链路尚未打通。

---

## 第6页：研究背景——三重挑战详解

针对这三重挑战，我提炼出三个科学问题：

- **资源难适配**对应的科学问题是：异构资源约束下模型设备协同优化机理，研究内容聚焦于异构边缘设备的重叠部署与动态执行调度机制；
- **部署难自动**对应的科学问题是：LLM驱动的架构搜索与反馈演化机制，研究内容聚焦于LLM驱动端侧模型自动化生成与硬件感知优化；
- **闭环难贯通**对应的科学问题是：边缘VLA模型压缩与快速适应耦合优化机理，研究内容聚焦于资源受限条件下VLA的压缩-适应协同优化。

---

## 第7页：研究定位

总体目标是：在资源受限、动态异构的边缘环境下，实现从算法到部署到应用的完整闭环，突破算力适配、模型部署的三重困境。

---

## 第8页：汇报提纲（过渡）

下面进入第三部分，具体的研究内容。

---

## 第9页：研究内容一——异构边缘协同推理（背景与概述）

第一项工作关注异构边缘协同推理。现有的边缘流水线推理方案在面对资源波动和设备故障时，需要重新部署，开销很大，而且往往只优化吞吐量，忽略了可靠性。

我们的工作有三个核心贡献：

第一，在**系统建模**方面，提出了边缘流水线的重叠部署与动态执行系统模型，建立了可靠性与吞吐量的联合优化模型；

第二，在**调度框架**方面，构建了部署-执行解耦的两阶段优化流程，支持无需重部署的实时自适应推理调度；

第三，在**算法设计**方面，提出了MOPSO多目标分区算法与RALE冗余扩展算法，实验表明成功率最高提升8.7倍，吞吐量提升1.4倍。

这项工作已投稿至IEEE/ACM TON，是CCF A类国际期刊。下一步将研究Transformer架构下Prefill与Decode阶段的异构多设备并行调度优化。

核心思想是：通过重叠部署加动态执行，利用冗余存储实现故障容忍，避免频繁重部署。

---

## 第10页：研究内容一——两阶段优化框架

具体来看两阶段优化框架。

**部署阶段**使用MOPSO加RALE算法确定重叠部署方案。其中MOPSO是多目标粒子群优化算法，每个粒子的每一维表示设备执行的层数，双目标是最大化吞吐量和可靠性。RALE是冗余感知层扩展算法，从执行分区出发，贪心地扩展存储范围，优先扩展增量负载小的方向。

**执行阶段**使用MOPSO动态选择执行分区，实现实时自适应调度。

---

## 第11页：研究内容一——实验结果

实验方面，我们在仿真环境下进行了100个执行周期的测试，模拟资源动态波动；同时搭建了真实测试床，使用4台异构设备包括PC、Jetson和树莓派，在VGG19、YOLONet、ResNet50三个模型上进行了验证。实验结果充分证明了我们方法在可靠性和吞吐量上的优势。

---

## 第12页：研究内容二——LLM驱动的端侧模型定制（背景与概述）

第二项工作关注LLM驱动的端侧模型定制。MCU资源极度受限，传统的压缩和轻量化设计方法以及硬件感知NAS搜索成本很高，且需要大量人工介入。

我们的核心贡献有三点：

第一，**端到端框架**：实现了从自然语言需求描述到可部署C代码的全流程自动化模型定制，比传统方法快100倍以上；

第二，**硬件感知机制**：设计了硬件在环过滤与历史性能库双重反馈机制，在训练前就验证架构可行性，并引导高效收敛；

第三，**智能体调度**：提出了状态隔离的多智能体调度机制，通过结构化摘要通信确保长周期优化过程的稳定性与可控性。

这项工作已投稿至IEEE TMC，是CCF A类、中科院1区国际期刊。下一步将研究MCU端模型的自动调试与故障诊断机制，并扩展至GPU、NPU、FPGA等异构设备。

---

## 第13页：研究内容二——多智能体协同框架

多智能体协同框架包含四个核心组件：

- **Supervisor**负责任务分解与调度，采用集中控制、状态隔离的设计；
- **Proposal Agent**负责生成候选架构，并进行硬件可行性过滤和历史性能学习；
- **Training Agent**负责训练与早停，在有限预算内评估性能；
- **Eval & Convert**模块负责资源评估和C代码生成，通过STM32Cube.AI工具链进行验证。

整个流程实现了从需求到部署的全自动化。

---

## 第14页：研究内容二——实验结果

实验在CIFAR-10和CIFAR-100数据集上进行，硬件约束设定为RAM不超过256KB、Flash不超过512KB，真实设备使用STM32F4、F7、H7系列MCU。实验结果验证了我们方法在资源受限条件下的有效性和实用性。

---

## 第15页：研究内容三——边缘高效VLA（上）

第三项工作是边缘高效VLA，即Vision-Language-Action模型在边缘端的高效部署。这是一个正在推进的研究方向，旨在解决VLA模型在资源受限边缘设备上的压缩与快速适应问题。

---

## 第16页：研究内容三——边缘高效VLA（下）

这部分工作目前正在深入研究中，核心目标是实现资源受限条件下VLA模型的压缩-适应协同优化，使得具身智能体能够在边缘设备上高效运行。

---

## 第17页：汇报提纲（过渡）

最后是第四部分，后续计划。

---

## 第18页：后续计划——研究进展

在论文方面，近期有多项投稿进展：2026年1月先后以通讯作者向IEEE TMC投稿2篇中科院1区/CCF A类论文，向IEEE TWC投稿1篇中科院1区论文，向IEEE/ACM TON投稿1篇中科院1区/CCF A类论文。此外，IEEE TNSE有1篇中科院2区论文处于Minor返修阶段。

在项目方面，2025年12月申报了中电10所第二重点实验室基金项目，经费20万，并参加了答辩；2025年10月参与了北理牵头的平安中国重点专项子课题。

在奖项方面，2025年11月获得了IEEE ISPCE-AS国际会议最佳论文奖。

---

## 第19页：后续计划——工作目标

**短期目标**方面：异构边缘协同推理和端侧模型定制两个方向，计划在3到4月完成期刊论文扩展投稿，目标是CCF A类会议论文；边缘高效VLA方向，计划在1个月内确定具体研究内容，形成研究Proposal。

**中期目标**方面：在科研论文上，推进视觉推理与边缘部署的联合工作，目标至少产出1篇论文；在边缘高效VLA方向，计划1年内完成1篇工作并投稿；同时积极参与团队项目申报。

---

## 第20页：结束页

以上就是我的汇报内容。感谢各位老师和同学的聆听，欢迎批评指正。谢谢！

---

*讲稿生成时间：2026-02-08*
