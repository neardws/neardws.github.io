#!/usr/bin/env python3
"""
é¢„æµ‹ç”Ÿæˆå™¨

åŸºäºæœ€è¿‘çš„äº¤äº’ã€å‘ç°å’Œè¶‹åŠ¿ï¼Œè‡ªåŠ¨ç”Ÿæˆæ–°é¢„æµ‹ã€‚
"""

import json
import random
from datetime import datetime, timedelta
from pathlib import Path

BASE_DIR = Path(__file__).parent.parent.parent / "curiosity-kernel"
PREDICTIONS_FILE = BASE_DIR / "predictions.json"
STATE_FILE = BASE_DIR / "state.json"
DISCOVERIES_FILE = BASE_DIR / "discoveries.md"

# é¢„æµ‹æ¨¡æ¿
PREDICTION_TEMPLATES = {
    "neil_behavior": [
        "Neil æ˜å¤©ä¼šç»§ç»­è®¨è®º {topic}",
        "Neil è¿™å‘¨ä¼šé—®å…³äº {topic} çš„é—®é¢˜",
        "Neil ä¼šå¯¹ {topic} çš„å®ç°ç»†èŠ‚æ„Ÿå…´è¶£",
    ],
    "project_state": [
        "{project} ä»“åº“æœ¬å‘¨ä¼šæœ‰æ–° commit",
        "{project} çš„é—®é¢˜ä¼šåœ¨ {days} å¤©å†…è¢«è§£å†³",
        "{project} çš„æ–‡æ¡£ä¼šè¢«æ›´æ–°",
    ],
    "world_events": [
        "{domain} é¢†åŸŸæœ¬å‘¨ä¼šæœ‰é‡è¦è®ºæ–‡å‘å¸ƒ",
        "{domain} ç¤¾åŒºä¼šè®¨è®º {topic}",
        "ä¼šæœ‰äººé—®å…³äº {topic} çš„é—®é¢˜",
    ],
    "system_state": [
        "Syncthing ä»Šå¤©ä¸ä¼šå‡ºé—®é¢˜",
        "å¥½å¥‡å¿ƒç³»ç»Ÿä»Šå¤©ä¼šæ¢ç´¢ {count} ä¸ª gap",
        "ä»Šå¤©çš„å·¥å…·è°ƒç”¨å¤±è´¥ç‡ä¼šä½äº {rate}%",
    ],
    "self_state": [
        "æˆ‘æ˜å¤©ä¼šç”Ÿæˆ {count} ä¸ªæ–°å‘ç°",
        "æˆ‘å¯¹ {topic} çš„ç†è§£ä¼šå¢åŠ ",
        "ç™½æ—¥æ¢¦å¼•æ“ä¼šè§¦å‘ {count} æ¬¡",
    ],
}

# å½“å‰æ´»è·ƒä¸»é¢˜
CURRENT_TOPICS = {
    "curiosity_kernel", "gap_generation", "daydream_engine", 
    "feedback_mechanism", "neil_model", "budget_management",
    "edge_intelligence", "HARL", "AgentEvolver"
}

PROJECTS = ["HARL", "clawd", "curiosity-kernel", "ObsidianVault"]
DOMAINS = ["Edge AI", "LLM Agents", "Reinforcement Learning", "Curiosity-driven Learning"]


def load_predictions():
    with open(PREDICTIONS_FILE) as f:
        return json.load(f)["predictions"]


def save_predictions(predictions):
    with open(PREDICTIONS_FILE, "w") as f:
        json.dump({"predictions": predictions}, f, indent=2, ensure_ascii=False)


def generate_prediction():
    """éšæœºç”Ÿæˆä¸€ä¸ªé¢„æµ‹"""
    domain = random.choice(list(PREDICTION_TEMPLATES.keys()))
    template = random.choice(PREDICTION_TEMPLATES[domain])
    
    # å¡«å……æ¨¡æ¿
    topic = random.choice(list(CURRENT_TOPICS))
    project = random.choice(PROJECTS)
    domain_name = random.choice(DOMAINS)
    
    prediction_text = template.format(
        topic=topic,
        project=project,
        domain=domain_name,
        days=random.randint(2, 7),
        count=random.randint(1, 3),
        rate=random.choice([10, 15, 20])
    )
    
    # è®¾ç½®éªŒè¯æ—¶é—´
    verify_after = datetime.now() + timedelta(days=random.randint(1, 7))
    
    return {
        "id": f"pred-{datetime.now().strftime('%Y%m%d-%H%M%S')}",
        "created": datetime.now().isoformat(),
        "domain": domain,
        "prediction": prediction_text,
        "confidence": round(random.uniform(0.3, 0.8), 1),
        "verify_after": verify_after.isoformat(),
        "verified": None,
        "actual": None,
        "surprise_score": None,
        "auto_generated": True
    }


def generate_predictions_from_discoveries():
    """åŸºäºæœ€è¿‘çš„å‘ç°ç”Ÿæˆé¢„æµ‹"""
    # è¯»å–æœ€è¿‘çš„å‘ç°
    with open(DISCOVERIES_FILE) as f:
        content = f.read()
    
    # æå–æœ€è¿‘çš„ä¸»é¢˜
    recent_topics = []
    for topic in CURRENT_TOPICS:
        if topic.lower() in content.lower():
            recent_topics.append(topic)
    
    predictions = []
    for topic in recent_topics[:2]:  # æœ€å¤š 2 ä¸ª
        template = random.choice(PREDICTION_TEMPLATES["self_state"])
        prediction_text = template.format(
            topic=topic,
            count=random.randint(1, 2),
            rate=15
        )
        
        verify_after = datetime.now() + timedelta(days=random.randint(1, 3))
        
        predictions.append({
            "id": f"pred-{datetime.now().strftime('%Y%m%d-%H%M%S')}-{topic[:3]}",
            "created": datetime.now().isoformat(),
            "domain": "self_state",
            "prediction": prediction_text,
            "confidence": round(random.uniform(0.4, 0.7), 1),
            "verify_after": verify_after.isoformat(),
            "verified": None,
            "actual": None,
            "surprise_score": None,
            "auto_generated": True,
            "source": "discovery_driven"
        })
    
    return predictions


def add_predictions(new_predictions):
    """æ·»åŠ æ–°é¢„æµ‹"""
    predictions = load_predictions()
    predictions.extend(new_predictions)
    save_predictions(predictions)
    return new_predictions


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python prediction_generator.py <command>")
        print("Commands:")
        print("  generate      - generate random predictions")
        print("  from_discoveries - generate predictions from recent discoveries")
        print("  show          - show all predictions")
        sys.exit(1)
    
    cmd = sys.argv[1]
    
    if cmd == "generate":
        count = int(sys.argv[2]) if len(sys.argv) > 2 else 2
        new_preds = [generate_prediction() for _ in range(count)]
        added = add_predictions(new_preds)
        print(f"âœ… Generated {len(added)} new predictions:")
        for p in added:
            print(f"  - [{p['confidence']:.0%}] {p['prediction'][:50]}...")
    
    elif cmd == "from_discoveries":
        new_preds = generate_predictions_from_discoveries()
        if new_preds:
            added = add_predictions(new_preds)
            print(f"âœ… Generated {len(added)} predictions from discoveries")
        else:
            print("No predictions generated (no recent discoveries)")
    
    elif cmd == "show":
        predictions = load_predictions()
        print(f"ğŸ“‹ Total predictions: {len(predictions)}")
        for p in predictions:
            status = "âœ“" if p.get("verified") else "â³"
            print(f"  [{status}] {p['prediction'][:60]}...")
