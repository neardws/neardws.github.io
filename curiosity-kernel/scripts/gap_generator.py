#!/usr/bin/env python3
"""
Gap è‡ªåŠ¨ç”Ÿæˆæ¨¡å—

ä»å‘ç°ä¸­è‡ªåŠ¨æå–æ–°çš„çŸ¥è¯†ç¼ºå£ï¼š
1. æå–å‘ç°ä¸­çš„å…³é”®è¯å’Œä¸»é¢˜
2. æœç´¢ supermemory æ‰¾åˆ°ç›¸å…³ä½†ä¸ç†è§£çš„ç‚¹
3. ç”Ÿæˆæ–°çš„ knowledge_gap
"""

import json
import re
from datetime import datetime
from pathlib import Path
import uuid

BASE_DIR = Path(__file__).parent.parent.parent / "curiosity-kernel"
STATE_FILE = BASE_DIR / "state.json"
DISCOVERIES_FILE = BASE_DIR / "discoveries.md"

# å…³é”®è¯æå–çš„ç®€å•è§„åˆ™
TOPIC_PATTERNS = {
    "edge_intelligence": r"è¾¹ç¼˜æ™ºèƒ½|edge\s*intelligence|èµ„æºå—é™|è®¡ç®—é¢„ç®—",
    "curiosity": r"å¥½å¥‡å¿ƒ|curiosity|æ¢ç´¢|tension|å¼ åŠ›",
    "system_design": r"ç³»ç»Ÿè®¾è®¡|æ¶æ„|æ¨¡å—|subsystem|å­ç³»ç»Ÿ",
    "learning": r"å­¦ä¹ |learning|é¢„æµ‹|prediction|æƒŠè®¶|surprise",
    "neil_research": r"HARL|å¼ºåŒ–å­¦ä¹ |è¾¹ç¼˜|vehicle|vehicular",
    "self_improvement": r"è‡ªæˆ‘|åæ€|ä¼˜åŒ–|æ”¹è¿›|meta",
}


def load_state():
    with open(STATE_FILE) as f:
        return json.load(f)


def save_state(state):
    with open(STATE_FILE, "w") as f:
        json.dump(state, f, indent=2, ensure_ascii=False)


def extract_topics(text):
    """ä»æ–‡æœ¬ä¸­æå–ä¸»é¢˜"""
    topics = []
    text_lower = text.lower()
    
    for topic, pattern in TOPIC_PATTERNS.items():
        if re.search(pattern, text_lower, re.IGNORECASE):
            topics.append(topic)
    
    return topics


def extract_key_phrases(text):
    """æå–å…³é”®çŸ­è¯­ï¼ˆç®€åŒ–ç‰ˆï¼šå¼•å·å†…å®¹å’Œé—®å·å¥å­ï¼‰"""
    phrases = []
    
    # å¼•å·å†…å®¹
    quoted = re.findall(r'[""ã€Œã€ã€ã€]([^""ã€Œã€ã€ã€]+)[""ã€Œã€ã€ã€]', text)
    phrases.extend(quoted)
    
    # é—®å·å¥å­
    questions = re.findall(r'([^ã€‚ï¼ï¼Ÿ\n]+\?)', text)
    phrases.extend(questions)
    
    return phrases


def generate_gap_from_discovery(discovery_text, discovery_id):
    """ä»å‘ç°ç”Ÿæˆæ–°çš„ knowledge gap"""
    topics = extract_topics(discovery_text)
    phrases = extract_key_phrases(discovery_text)
    
    # åŸºäº topic ç»„åˆç”Ÿæˆé—®é¢˜
    if len(topics) >= 2:
        gap_question = f"{topics[0].replace('_', ' ')} å’Œ {topics[1].replace('_', ' ')} çš„ç»“åˆç‚¹åœ¨å“ªé‡Œï¼Ÿ"
    elif len(topics) == 1:
        gap_question = f"{topics[0].replace('_', ' ')} è¿™ä¸ªæ–¹å‘è¿˜æœ‰å“ªäº›æˆ‘æ²¡ç†è§£çš„ï¼Ÿ"
    elif phrases:
        gap_question = f"å…³äº \"{phrases[0][:30]}\" èƒŒåçš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ"
    else:
        return None  # æ— æ³•ç”Ÿæˆæœ‰æ„ä¹‰çš„ gap
    
    return {
        "id": f"gap-{uuid.uuid4().hex[:8]}",
        "domain": topics[0] if topics else "general",
        "question": gap_question,
        "importance": 0.6,
        "uncertainty": 0.8,
        "created": datetime.now().isoformat(),
        "source": "discovery_driven",
        "related_discovery": discovery_id
    }


def generate_gaps_from_recent_discoveries(limit=3):
    """ä»æœ€è¿‘çš„å‘ç°ç”Ÿæˆæ–°çš„ gap"""
    state = load_state()
    
    # è¯»å– discoveries.md
    with open(DISCOVERIES_FILE) as f:
        content = f.read()
    
    # æå–æœ€è¿‘çš„å‘ç°
    discovery_pattern = r'## (#\d+)[^#]*?(\d{4}-\d{2}-\d{2})[^#]*?\*\*å‘ç°[ï¼š:]\*\*\s*([^\n]+)'
    matches = re.findall(discovery_pattern, content)
    
    new_gaps = []
    existing_questions = [g["question"] for g in state["knowledge_gaps"]]
    
    for discovery_id, date, discovery_text in matches[:limit]:
        gap = generate_gap_from_discovery(discovery_text, discovery_id)
        
        if gap and gap["question"] not in existing_questions:
            new_gaps.append(gap)
            existing_questions.append(gap["question"])
    
    # æ·»åŠ åˆ° state
    if new_gaps:
        state["knowledge_gaps"].extend(new_gaps)
        save_state(state)
    
    return new_gaps


def generate_gap_from_surprise(prediction, surprise):
    """ä»é«˜æƒŠè®¶åº¦é¢„æµ‹ç”Ÿæˆæ–° gap"""
    return {
        "id": f"gap-{uuid.uuid4().hex[:8]}",
        "domain": prediction.get("domain", "general"),
        "question": f"ä¸ºä»€ä¹ˆæˆ‘å¯¹ '{prediction['prediction'][:50]}...' çš„é¢„æµ‹é”™äº†ï¼Ÿç½®ä¿¡åº¦ {prediction['confidence']:.0%}",
        "importance": min(surprise + 0.3, 1.0),
        "uncertainty": 0.9,
        "created": datetime.now().isoformat(),
        "source": "surprise_driven",
        "related_prediction": prediction["id"]
    }


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python gap_generator.py <command>")
        print("Commands:")
        print("  generate    - generate gaps from recent discoveries")
        print("  show        - show current knowledge gaps")
        sys.exit(1)
    
    cmd = sys.argv[1]
    
    if cmd == "generate":
        new_gaps = generate_gaps_from_recent_discoveries()
        if new_gaps:
            print(f"âœ… Generated {len(new_gaps)} new gaps:")
            for gap in new_gaps:
                print(f"  - {gap['id']}: {gap['question'][:50]}...")
        else:
            print("No new gaps generated (all topics already covered)")
    
    elif cmd == "show":
        state = load_state()
        print(f"ğŸ“‹ Current knowledge gaps ({len(state['knowledge_gaps'])}):")
        for gap in state["knowledge_gaps"]:
            importance = gap.get("importance", 0.5)
            uncertainty = gap.get("uncertainty", 0.5)
            tension_score = importance * uncertainty
            print(f"  [{tension_score:.2f}] {gap['question'][:60]}...")
